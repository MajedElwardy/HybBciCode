count <- 1
for (iS in 1:nSubs){
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
subject[count] <- allSubs[iS]
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
temp <- subset(accData, subject == allSubs[iS])
temp <- subset(temp, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
correctnessCount[count] <- sum(temp$correctness)
correctnessRatio[count] <- sum(temp$correctness) / length((temp$correctness))
count <- count+1
}
}
}
}
accDataCount <- data.frame(subject, classifier, frequency, nRep, correctnessCount, correctnessRatio)
#################################################################################################################
library(ggplot2)
library(scales)
dataToPlot <- subset(accDataCount, classifier=="normal")
pp <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp <- pp + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp <- pp + facet_wrap( ~subject )
pp <- cleanPlot(pp)
pp <- pp + theme(legend.position=c(0.8334,0.1667))
pp
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3 <- pp3 + geom_smooth(method="lm", se=F)
pp3 <- cleanPlot(pp3)
pp3 <- pp3 + theme(legend.position=c(0.8334,0.1667))
pp3
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3
allFreqs  <- levels(accData$frequency)
allNreps  <- unique(accData$nRep)
allClassif<- levels(accData$classifier)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
nClassif<- length(allClassif)
frequency   <- rep(NA, nFreqs*nReps*nClassif)
nRep        <- rep(NA, nFreqs*nReps*nClassif)
classifier  <- rep(NA, nFreqs*nReps*nClassif)
correctnessRatio <- rep(NA, nFreqs*nReps*nClassif)
correctnessRatioLogit <- rep(NA, nFreqs*nReps*nClassif)
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
temp <- subset(accData, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
correctnessRatio[count] <- mean(temp$correctness)
correctnessRatioLogit[count] <- log( mean(temp$correctness) / (1-mean(temp$correctness)) )
count <- count+1
}
}
}
accDataGdMean <- data.frame(classifier, frequency, nRep, correctnessRatio, correctnessRatioLogit)
dataToPlot <- subset(accDataGdMean, classifier=="normal")
pp1 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp1 <- pp1 + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
# pp1 <- pp1 + scale_y_continuous(trans=logit_trans())
pp1 <- cleanPlot(pp1)
pp1
dataToPlot <- subset(accDataGdMean, classifier=="normal")
pp2 <- ggplot( dataToPlot, aes(nRep, correctnessRatioLogit, colour=frequency, shape=frequency) )
pp2 <- pp2 + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp2 <- cleanPlot(pp2)
pp2 + geom_smooth(method="lm", se=F)
dataToPlot <- subset(accDataCount, classifier=="normal")
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3
pp3 <- pp3 + geom_smooth(method="lm", se=F)
pp3
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3 <- cleanPlot(pp3)
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3
dataToPlot <- subset(accDataGdMean, classifier=="normal")
pp1 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp1 <- pp1 + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp1 <- pp1 + scale_y_continuous(trans=logit_trans())
pp1
pp1 <- pp1 + scale_y_continuous(trans=logit_trans())
pp1 <- cleanPlot(pp1)
pp1
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3
setwd("d:/KULeuven/PhD/Work/Hybrid-BCI/HybBciCode/dataAnalysisCodes/watchERP/02-ter-p3Classification/")
rm(list = ls())
source("createDataFrame.R")
source("cleanPlot.R")
#################################################################################################################
allSubs   <- levels(accData$subject)
allFreqs  <- levels(accData$frequency)
allNreps  <- unique(accData$nRep)
allClassif<- levels(accData$classifier)
nSubs   <- length(allSubs)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
nClassif<- length(allClassif)
subject     <- rep(NA, nSubs*nFreqs*nReps*nClassif)
frequency   <- rep(NA, nSubs*nFreqs*nReps*nClassif)
nRep        <- rep(NA, nSubs*nFreqs*nReps*nClassif)
classifier  <- rep(NA, nSubs*nFreqs*nReps*nClassif)
correctnessCount <- rep(NA, nSubs*nFreqs*nReps*nClassif)
correctnessRatio <- rep(NA, nSubs*nFreqs*nReps*nClassif)
count <- 1
for (iS in 1:nSubs){
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
subject[count] <- allSubs[iS]
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
temp <- subset(accData, subject == allSubs[iS])
temp <- subset(temp, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
correctnessCount[count] <- sum(temp$correctness)
correctnessRatio[count] <- sum(temp$correctness) / length((temp$correctness))
count <- count+1
}
}
}
}
accDataCount <- data.frame(subject, classifier, frequency, nRep, correctnessCount, correctnessRatio)
#################################################################################################################
library(ggplot2)
library(scales)
dataToPlot <- subset(accDataCount, classifier=="normal")
pp <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp <- pp + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp <- pp + facet_wrap( ~subject )
pp <- cleanPlot(pp)
pp <- pp + theme(legend.position=c(0.8334,0.1667))
pp
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3 <- cleanPlot(pp3)
pp3 <- pp3 + geom_smooth(method="lm", se=F)
pp3 <- pp3 + theme(legend.position=c(0.8334,0.1667))
pp3
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3
allFreqs  <- levels(accData$frequency)
allNreps  <- unique(accData$nRep)
allClassif<- levels(accData$classifier)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
nClassif<- length(allClassif)
frequency   <- rep(NA, nFreqs*nReps*nClassif)
nRep        <- rep(NA, nFreqs*nReps*nClassif)
classifier  <- rep(NA, nFreqs*nReps*nClassif)
correctnessRatio <- rep(NA, nFreqs*nReps*nClassif)
correctnessRatioLogit <- rep(NA, nFreqs*nReps*nClassif)
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
temp <- subset(accData, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
correctnessRatio[count] <- mean(temp$correctness)
correctnessRatioLogit[count] <- log( mean(temp$correctness) / (1-mean(temp$correctness)) )
count <- count+1
}
}
}
accDataGdMean <- data.frame(classifier, frequency, nRep, correctnessRatio, correctnessRatioLogit)
dataToPlot <- subset(accDataGdMean, classifier=="normal")
pp1 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp1 <- pp1 + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp1 <- pp1 + scale_y_continuous(trans=logit_trans())
pp1 <- cleanPlot(pp1)
pp1
pp1 + geom_smooth(method="lm", se=F)
dataToPlot <- subset(accDataCount, classifier=="normal")
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3 <- cleanPlot(pp3)
p
pp3
pp3 <- pp3 + scale_y_continuous(trans=logit_trans())
pp3
pp3 <- pp3 + scale_y_continuous(limits=c(0, 3))
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3 <- cleanPlot(pp3)
pp3
pp3 <- pp3 + scale_y_continuous(limits=c(0, 3), trans=logit_trans())
pp3
setwd("d:/KULeuven/PhD/Work/Hybrid-BCI/HybBciCode/dataAnalysisCodes/watchERP/02-ter-p3Classification/")
rm(list = ls())
library(ggplot2)
library(lme4)
library(LMERConvenienceFunctions)
library(languageR)
source("createDataFrame.R")
source("cleanPlot.R")
#################################################################################################################
accData1 <- subset(accData, classifier=="normal")
accData1 <- subset(accData1, select = -c(classifier, foldTest))
str(accData1)
summary(accData1)
#################################################################################################################
pp <- ggplot( accData1, aes(nRep, correctness, colour=condition, shape=condition) )
pp <- pp + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
# pp <- pp + stat_summary(fun.y = mean, geom="point", position = position_dodge(.5))
# pp <- pp + stat_summary(fun.data = mean_cl_normal, geom = "pointrange", width = 0.2, position = position_dodge(.5), size = 1)
pp <- pp + facet_wrap( ~subject )
pp <- cleanPlot(pp)
pp <- pp + theme(legend.position=c(0.8334,0.1667))
pp
#################################################################################################################
f0Vs857_10_12_15    = c(-4, 1, 1, 1, 1)     # oddball vs. hybrid
f857Vs10_12_15      = c(0, -3, 1, 1, 1)     # hybrid-8-57Hz vs. hybrid-10-12-15-Hz
f10Vs12_15          = c(0, 0, -2, 1, 1)     # hybrid-10Hz vs. hybrid-12-15-Hz
f12Vs15             = c(0, 0, 0, -1, 1)     # hybrid-12Hz vs. hybrid-15-Hz
contrasts(accData1$frequency) <- cbind(
f0Vs857_10_12_15
, f857Vs10_12_15
, f10Vs12_15
, f12Vs15
)
#################################################################################################################
# lmH4 <- lmer( correctness ~ nRep*frequency + ( correctness | subject ), data = accData1, family = binomial )
# lmH3 <- lmer( correctness ~ nRep*frequency + ( 1 | subject ), data = accData1, family = binomial )
# lmH2 <- lmer( correctness ~ nRep + frequency + ( 1 | subject ), data = accData1, family = binomial )
# lmH1a <- lmer( correctness ~ nRep + ( 1 | subject ), data = accData1, family = binomial )
# lmH1b <- lmer( correctness ~ frequency + ( 1 | subject ), data = accData1, family = binomial )
# lmH0 <- lmer( correctness ~ ( 1 | subject ), data = accData1, family = binomial )
#
# anova( lmH0, lmH1a, lmH2, lmH3 ) #, lmH4 )
# anova( lmH0, lmH1b, lmH2, lmH3 ) #, lmH4 )
#################################################################################################################
accData1$nRepFac <- as.factor(accData1$nRep)
lmH3 <- lmer( correctness ~ frequency * nRepFac + ( 1 | subject/nRepFac ), data = accData1, family = binomial )
lmH2 <- lmer( correctness ~ frequency + nRep + ( 1 | subject:nRep ), data = accData1, family = binomial )
lmH2 <- lmer( correctness ~ frequency + ( 1 | subject:nRep ), data = accData1, family = binomial )
lmH2 <- lmer( correctness ~ frequency + ( 1 | nRep:subject ), data = accData1, family = binomial )
lmH2 <- lmer( correctness ~ frequency + ( 1 | nRep/subject ), data = accData1, family = binomial )
lmH2 <- lmer( correctness ~ frequency + ( 1 | nRep\subject ), data = accData1, family = binomial )
setwd("d:/KULeuven/PhD/Work/Hybrid-BCI/HybBciCode/dataAnalysisCodes/watchERP/02-ter-p3Classification/")
rm(list = ls())
library(ggplot2)
library(lme4)
library(LMERConvenienceFunctions)
library(languageR)
source("createDataFrame.R")
source("cleanPlot.R")
#################################################################################################################
accData1 <- subset(accData, classifier=="normal")
accData1 <- subset(accData1, select = -c(classifier, foldTest))
str(accData1)
summary(accData1)
#################################################################################################################
pp <- ggplot( accData1, aes(nRep, correctness, colour=condition, shape=condition) )
pp <- pp + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
# pp <- pp + stat_summary(fun.y = mean, geom="point", position = position_dodge(.5))
# pp <- pp + stat_summary(fun.data = mean_cl_normal, geom = "pointrange", width = 0.2, position = position_dodge(.5), size = 1)
pp <- pp + facet_wrap( ~subject )
pp <- cleanPlot(pp)
pp <- pp + theme(legend.position=c(0.8334,0.1667))
pp
#################################################################################################################
f0Vs857_10_12_15    = c(-4, 1, 1, 1, 1)     # oddball vs. hybrid
f857Vs10_12_15      = c(0, -3, 1, 1, 1)     # hybrid-8-57Hz vs. hybrid-10-12-15-Hz
f10Vs12_15          = c(0, 0, -2, 1, 1)     # hybrid-10Hz vs. hybrid-12-15-Hz
f12Vs15             = c(0, 0, 0, -1, 1)     # hybrid-12Hz vs. hybrid-15-Hz
contrasts(accData1$frequency) <- cbind(
f0Vs857_10_12_15
, f857Vs10_12_15
, f10Vs12_15
, f12Vs15
)
#################################################################################################################
# lmH4 <- lmer( correctness ~ nRep*frequency + ( correctness | subject ), data = accData1, family = binomial )
# lmH3 <- lmer( correctness ~ nRep*frequency + ( 1 | subject ), data = accData1, family = binomial )
# lmH2 <- lmer( correctness ~ nRep + frequency + ( 1 | subject ), data = accData1, family = binomial )
# lmH1a <- lmer( correctness ~ nRep + ( 1 | subject ), data = accData1, family = binomial )
# lmH1b <- lmer( correctness ~ frequency + ( 1 | subject ), data = accData1, family = binomial )
# lmH0 <- lmer( correctness ~ ( 1 | subject ), data = accData1, family = binomial )
#
# anova( lmH0, lmH1a, lmH2, lmH3 ) #, lmH4 )
# anova( lmH0, lmH1b, lmH2, lmH3 ) #, lmH4 )
#################################################################################################################
accData1$nRepFac <- as.factor(accData1$nRep)
lmH3 <- lmer( correctness ~ frequency * nRepFac + ( 1 | subject/nRepFac ), data = accData1, family = binomial )
lmH2 <- lmer( correctness ~ frequency + nRepFac + ( 1 | subject/nRepFac ), data = accData1, family = binomial )
lmH1a <- lmer( correctness ~ frequency + ( 1 | subject/nRepFac ), data = accData1, family = binomial )
lmH1b <- lmer( correctness ~ nRepFac + ( 1 | subject/nRepFac ), data = accData1, family = binomial )
lmH0 <- lmer( correctness ~ ( 1 | subject/nRepFac ), data = accData1, family = binomial )
anova( lmH0, lmH1a, lmH2, lmH3 ) #, lmH4 )
anova( lmH0, lmH1b, lmH2, lmH3 ) #, lmH4 )
#################################################################################################################
allSubs   <- levels(accData1$subject)
allFreqs  <- levels(accData1$frequency)
allNreps  <- unique(accData1$nRep)
nSubs   <- length(allSubs)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
ID     <- rep(NA, length(accData1$subject))
count <- 1
for (iS in 1:nSubs){
for (iF in 1:nFreqs){
for (iR in 1:nReps){
temp <- subset(accData1, subject == allSubs[iS])
temp <- subset(temp, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
for (iT in 1:length(temp$subject)){
ID[count] <- 1000*iS + allNreps[iR]
count <- count+1
}
}
}
}
accData1$ID <- ID
lmH13 <- lmer( correctness ~ frequency * nRep + ( 1 | subject ) + ( 1 | ID ), data = accData1, family = binomial )
lmH12 <- lmer( correctness ~ frequency + nRep + ( 1 | subject ) + ( 1 | ID ), data = accData1, family = binomial )
lmH11a <- lmer( correctness ~ frequency + ( 1 | subject ) + ( 1 | ID ), data = accData1, family = binomial )
lmH11b <- lmer( correctness ~ nRep + ( 1 | subject ) + ( 1 | ID ), data = accData1, family = binomial )
lmH10 <- lmer( correctness ~ ( 1 | subject ) + ( 1 | ID ), data = accData1, family = binomial )
anova( lmH10, lmH11a, lmH12, lmH13 ) #, lmH4 )
anova( lmH10, lmH11b, lmH12, lmH13 ) #, lmH4 )
lmH0 <- lmer( correctness ~ ( 1 | subject/nRep ), data = accData1, family = binomial )
setwd("d:/KULeuven/PhD/Work/Hybrid-BCI/HybBciCode/dataAnalysisCodes/watchERP/02-ter-p3Classification/")
rm(list = ls())
source("createDataFrame.R")
source("cleanPlot.R")
#################################################################################################################
allSubs   <- levels(accData$subject)
allFreqs  <- levels(accData$frequency)
allNreps  <- unique(accData$nRep)
allClassif<- levels(accData$classifier)
nSubs   <- length(allSubs)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
nClassif<- length(allClassif)
subject     <- rep(NA, nSubs*nFreqs*nReps*nClassif)
frequency   <- rep(NA, nSubs*nFreqs*nReps*nClassif)
nRep        <- rep(NA, nSubs*nFreqs*nReps*nClassif)
classifier  <- rep(NA, nSubs*nFreqs*nReps*nClassif)
correctnessCount <- rep(NA, nSubs*nFreqs*nReps*nClassif)
correctnessRatio <- rep(NA, nSubs*nFreqs*nReps*nClassif)
count <- 1
for (iS in 1:nSubs){
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
subject[count] <- allSubs[iS]
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
temp <- subset(accData, subject == allSubs[iS])
temp <- subset(temp, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
correctnessCount[count] <- sum(temp$correctness)
correctnessRatio[count] <- sum(temp$correctness) / length((temp$correctness))
count <- count+1
}
}
}
}
accDataCount <- data.frame(subject, classifier, frequency, nRep, correctnessCount, correctnessRatio)
#################################################################################################################
library(ggplot2)
library(scales)
dataToPlot <- subset(accDataCount, classifier=="normal")
pp <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp <- pp + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp <- pp + facet_wrap( ~subject )
pp <- cleanPlot(pp)
pp <- pp + theme(legend.position=c(0.8334,0.1667))
pp
pp3 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp3 <- pp3 + stat_summary(fun.y = mean, geom="point",  position = position_jitter(w = 0.2, h = 0), size = 3)
pp3 <- cleanPlot(pp3)
pp3 <- pp3 + scale_y_continuous(limits=c(0, 3), trans=logit_trans())
pp3 <- pp3 + scale_y_continuous(limits=c(0, 3))
pp3 <- pp3 + geom_smooth(method="lm", se=F)
pp3 <- pp3 + theme(legend.position=c(0.8334,0.1667))
pp3
#################################################################################################################
# average over subjects and plot logit
allFreqs  <- levels(accData$frequency)
allNreps  <- unique(accData$nRep)
allClassif<- levels(accData$classifier)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
nClassif<- length(allClassif)
frequency   <- rep(NA, nFreqs*nReps*nClassif)
nRep        <- rep(NA, nFreqs*nReps*nClassif)
classifier  <- rep(NA, nFreqs*nReps*nClassif)
correctnessRatio <- rep(NA, nFreqs*nReps*nClassif)
correctnessRatioLogit <- rep(NA, nFreqs*nReps*nClassif)
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
temp <- subset(accData, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
correctnessRatio[count] <- mean(temp$correctness)
correctnessRatioLogit[count] <- log( mean(temp$correctness) / (1-mean(temp$correctness)) )
count <- count+1
}
}
}
accDataGdMean <- data.frame(classifier, frequency, nRep, correctnessRatio, correctnessRatioLogit)
# library(scales)
dataToPlot <- subset(accDataGdMean, classifier=="normal")
pp1 <- ggplot( dataToPlot, aes(nRep, correctnessRatio, colour=frequency, shape=frequency) )
pp1 <- pp1 + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp1 <- pp1 + scale_y_continuous(trans=logit_trans())
pp1 <- cleanPlot(pp1)
# pp1 + geom_smooth(method="lm", se=F)
pp1
dataToPlot <- subset(accDataGdMean, classifier=="normal")
pp2 <- ggplot( dataToPlot, aes(nRep, correctnessRatioLogit, colour=frequency, shape=frequency) )
pp2 <- pp2 + geom_point(position = position_jitter(w = 0.2, h = 0), size = 3)
pp2 <- cleanPlot(pp2)
pp2 + geom_smooth(method="lm", se=F)
#################################################################################################################
library(lme4)
accDataCount1 <- subset(accDataCount, classifier=="normal")
accDataCount1 <- subset(accDataCount1, select = -c(classifier))
accDataCount1$nRep <- as.factor(accDataCount1$nRep)
str(accDataCount1)
summary(accDataCount1)
lmH1 <- lmer( correctness ~ frequency + ( 1 | subject/nRep ), data = accDataCount1 )
lmH1 <- lmer( correctnessCount ~ frequency + ( 1 | subject/nRep ), data = accDataCount1 )
setwd("d:/KULeuven/PhD/Work/Hybrid-BCI/HybBciCode/dataAnalysisCodes/watchERP/02-ter-p3Classification/")
rm(list = ls())
source("createDataFrame.R")
source("cleanPlot.R")
str(accData)
setwd("d:/KULeuven/PhD/Work/Hybrid-BCI/HybBciCode/dataAnalysisCodes/watchERP/02-ter-p3Classification/")
rm(list = ls())
source("createDataFrame.R")
source("cleanPlot.R")
#################################################################################################################
allSubs   <- levels(accData$subject)
allFreqs  <- levels(accData$frequency)
allNreps  <- unique(accData$nRep)
allClassif<- levels(accData$classifier)
nSubs   <- length(allSubs)
nFreqs  <- length(allFreqs)
nReps   <- length(allNreps)
nClassif<- length(allClassif)
subject     <- rep(NA, nSubs*nFreqs*nReps*nClassif)
frequency   <- rep(NA, nSubs*nFreqs*nReps*nClassif)
nRep        <- rep(NA, nSubs*nFreqs*nReps*nClassif)
classifier  <- rep(NA, nSubs*nFreqs*nReps*nClassif)
correctnessCount <- rep(NA, nSubs*nFreqs*nReps*nClassif)
correctnessRatio <- rep(NA, nSubs*nFreqs*nReps*nClassif)
count <- 1
for (iS in 1:nSubs){
for (iF in 1:nFreqs){
for (iR in 1:nReps){
for (iC in 1:nClassif){
subject[count] <- allSubs[iS]
frequency[count] <- allFreqs[iF]
nRep[count] <- allNreps[iR]
classifier[count] <- allClassif[iC]
temp <- subset(accData, subject == allSubs[iS])
temp <- subset(temp, frequency == allFreqs[iF])
temp <- subset(temp, nRep == allNreps[iR])
temp <- subset(temp, classifier == allClassif[iC])
correctnessCount[count] <- sum(temp$correctness)
correctnessRatio[count] <- sum(temp$correctness) / length((temp$correctness))
count <- count+1
}
}
}
}
accDataCount <- data.frame(subject, classifier, frequency, nRep, correctnessCount, correctnessRatio)
#################################################################################################################
str(accDataCount)
accDataCount1 <- subset(accDataCount, classifier=="normal")
accDataCount1 <- subset(accDataCount1, select = -c(classifier))
str(accDataCount1)
summary(accDataCount1)
lmH1 <- lmer( correctnessCount ~ frequency + ( 1 | subject/nRep ), data = accDataCount1 )
lmH1 <- lmer( correctnessCount ~ frequency + ( 1 | nRep/subject ), data = accDataCount1 )
